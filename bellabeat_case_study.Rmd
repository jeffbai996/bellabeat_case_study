---
title: "Bellabeat Case Study - How Can a Wellness Technology Company Play It Smart?"
author: "Jeff Bai"
date: '2022-07-14'
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css, echo=FALSE}
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
```

This case study is a capstone project for the Google Data Analytics Professional Certificate. The following analysis was completed for Course 8 - Case Study 2. For the purposes of this case study, I assume the role of a Junior Data Analyst working on the Marketing Analytics team at Bellabeat, a high-tech company that manufactures health-focused smart products for women.

# Case Introduction

### About Bellabeat
Bellabeat was founded in 2013 by Urška Sršen and Sando Mur. Leveraging Sršen's background as an artist, Bellabeat has developed beautifully designed technology that informs and inspires women around the world. By collecting data on activity, sleep, stress, and reproductive health, Bellabeat empowers women with actionable insights into their health and habits. 

By 2016, Bellabeat achieved a worldwide presence and launched a variety of products. These products are available through online retailers or through Bellabeat's e-commerce channel. To engage their customer base, Bellabeat has invested in traditional advertising media (radio, billboards, print, TV), in addition to extensive digital marketing (Google Ads/Search, Facebook, Instagram, YouTube).

Bellabeat has 5 main products:

1. **Bellabeat app**  
The Bellabeat app provides users with health data related to their activity, sleep, stress, menstrual cycle, and mindfulness habits. This data can help users better understand their current habits and make healthy decisions. The Bellabeat app connects to their line of smart wellness products.
2. **Leaf**  
Bellabeat’s classic wellness tracker can be worn as a bracelet, necklace, or clip. The Leaf tracker connects to the Bellabeat app to track activity, sleep, and stress.
3. **Time**  
This wellness watch combines the timeless look of a classic timepiece with smart technology to track user activity, sleep, and stress. The Time watch connects to the Bellabeat app to provide you with insights into your daily wellness.
4. **Spring**  
This is a water bottle that tracks daily water intake using smart technology to ensure that you are appropriately hydrated throughout the day. The Spring bottle connects to the Bellabeat app to track your hydration levels.
5. **Bellabeat membership**  
Bellabeat also offers a subscription-based membership program for users. Membership gives users 24/7 access to fully personalized guidance on nutrition, activity, sleep, health and beauty, and mindfulness based on their lifestyle and goals.

### Scenario and Key Questions
Chief Creative Officer Urška Sršen knows that an analysis of Bellabeat's available consumer data would reveal more opportunities for growth. She has tasked the Marketing Analytics team with analyzing usage data from a public dataset in order to gain insight on how people are using smart fitness trackers. With this information, Sršen hopes to receive high-level recommendations for how these trends can inform Bellabeat's marketing strategy for their product moving forward.

Our team will rely on three key guiding questions for the direction of our analysis:

1. **What are some trends in smart device usage?**
2. **How could these trends apply to Bellabeat customers?**
3. **How could these trends help influence Bellabeat marketing strategy?**

### Stakeholders

**Urška Sršen**  
Bellabeat's co-founder and Chief Creative Officer

**Sando Mur**  
Mathematician and Bellabeat's cofounder; key member of the Bellabeat executive team

**Bellabeat Marketing Analytics team**  
A team of data analysts responsible for collecting, analyzing, and reporting data that informs Bellabeat's marketing strategy

### Scope of Work
Our team will produce a report with the following deliverables:

* A clear summary of the business task
* A description of all data sources used
* Documentation of any cleaning or manipulation of data
* A summary of the analysis
* Supporting visualizations and key findings
* Top high-level content recommendations based on analysis

# Deliverables

## Business Task
With smart devices a key pillar of Bellabeat's business, our team aims to dive deep into usage data, drawing insights and conclusions from how smart devices are used in general, in order to inform Bellabeat's future marketing strategy and drive future growth.

## Data Sources
The dataset used in this analysis is [Fitbit Fitness Tracker Data](https://www.kaggle.com/datasets/arashnic/fitbit), sourced from the personal fitness tracker data of 30 Fitbit users. It contains metrics such as physical activity output, heart rate, sleep patterns, and daily activity. This dataset was made available for this analysis through Mobius, a Kaggle contributor. The dataset is in the public domain, under the terms of Creative Commons CC0 1.0 Universal.

### ROCCC analysis
To evaluate the quality of this dataset from a high-level perspective, we will use the ROCCC system.

**Reliable?**  
A large part of the dataset is sourced from usage data from fitness trackers. Only one subset - weight log info - relies on self-reporting. Since Fitbit is a very well-established maker of fitness trackers, we will assume that the data generated by their devices **is reliable and accurate**. 

One important caveat to note is, since we have little information on the 30 individuals represented in the dataset (no age, gender, etc.), results may be skewed if the sample is not representative of the general population of smart tracker users.

**Original?**  
This dataset is **not original** to Fitbit, as it was collected by third-parties via Amazon Mechanical Turk.

**Comprehensive?**  
The dataset includes activity rate, calories burned, exercise intensity, steps taken, heartrate, and sleep duration. The data is further broken down into daily aggregated data, hourly data, and minute-by-minute data. For the purposes of our analysis and in the context of our business task, this dataset **is comprehensive**.

**Current?**  
This dataset date range is from April to May 2016, and is **not current**. At the same time, fitness tracker users' activity patterns are not likely to have changed in the years since the data was collected, and is therefore unlikely to skew our results.

**Cited?**  
This dataset's source, authors, and collection method are well documented and can be found on the dataset's [web page](https://www.kaggle.com/datasets/arashnic/fitbit).

## Data Cleaning
Since our stakeholders desire a high-level analysis of usage trends instead of minute-by-minute activity by individual, we will not include hourly, by-minute, and by-second data for heartrate, intensity, steps, and sleep in our analysis. This leaves us with 6 .csv files:

* dailyActivity_merged.csv
* dailyCalories_merged.csv
* dailyIntensities_merged.csv
* dailySteps_merged.csv
* sleepDay_merged.csv
* weightLogInfo_merged.csv

Exploring the data within Google Sheets, we found that dailyCalories_merged, dailyIntensities_merged, and dailySteps_merged are simply subsets of dailyActivity_merged. We can therefore remove these 3 .csv files without losing any data.

We'll also truncate the titles of our remaining 3 .csv files, removing "_merged" as it is redundant and needlessly makes our data more difficult to manipulate. This leaves us with:

* dailyActivity.csv
* sleepDay.csv
* weightLogInfo.csv

### Cleaning with BigQuery
Before digging deeper with R, we first want to learn more about the attributes of our selected datasets with Google's BigQuery.

***Note**: sleepDay.csv and weightLogInfo.csv were not able to be uploaded to BigQuery in their raw form as the timestamp column could not be parsed, either with auto or manual schemas. Since the data here were collected on a daily basis, we removed the time and reformatted these columns into a MM/DD/YYYY format with Google Sheets before uploading to BigQuery.*

**Distinct IDs**  
Let's take a look at how many distinct IDs (users) are represented in our data:

```{}
SELECT COUNT(DISTINCT Id) AS distinct_ids
FROM `marine-actor-233222.bellabeat_data.dailyActivity`

SELECT COUNT(DISTINCT Id) AS distinct_ids
FROM `marine-actor-233222.bellabeat_data.sleepDay`

SELECT COUNT(DISTINCT Id) AS distinct_ids
FROM `marine-actor-233222.bellabeat_data.weightLogInfo`
```

Our query results showed that dailyActivity contains **33 unique IDs**. 

sleepDay contains **24** unique IDs.

weightLogInfo contains **8** unique IDs.

sleepDay and weightLogInfo both contain a smaller sample size (n < 30) than is required for the central limit theorem to hold. However, these two pieces of data contain unique metrics (sleep, weight) not represented in the rest of the data. As such, we will retain these two tables for further analysis while keeping in mind their limited statistical power.

**Invalid Records**  
We also want to see how many invalid records exist in our data.

From inspecting the data table preview on BigQuery, we found that there were many records with a very low number of steps. As the average person takes around 5,000 steps per day, we'll count records with less than 500 steps per day as invalid.

We select all records where TotalSteps is less than 500:

```{}
SELECT *
FROM `marine-actor-233222.bellabeat_data.dailyActivity` 
WHERE TotalSteps < 500
```

Our query returned 98 rows where TotalSteps is less than 500. As expected, these rows also have low values for TotalDistance, TrackerDistance, LoggedActivitiesDistance, and so on. We will assume these records are a result of the user not tracking their activity for those days. We will drop these rows from our dataset with R later on.

We'll also filter sleepDay and see if there are any records where TotalMinutesAsleep equals 0:

```{}
SELECT *
FROM `marine-actor-233222.bellabeat_data.sleepDay` 
WHERE TotalMinutesAsleep = 0
```

This query returned no results - we do not have any invalid records in sleepDay.

We then repeat this process for weightLogInfo, using the column WeightKg as our filter:

```{}
SELECT *
FROM `marine-actor-233222.bellabeat_data.weightLogInfo` 
WHERE WeightKg = 0
```

This query again returned no results.

### Cleaning with R

**Loading required packages**  
We first load the tidyverse and other required packages:

```{r eval=FALSE}
library(tidyverse)
library(janitor)
library(skimr)
library(lubridate)
```

**Loading .csv files into data frames**  
We'll then load the .csv files we chose earlier into data frames:

```{r eval=FALSE}
dailyActivity <- read_csv("datasets/dailyActivity.csv")
sleepDay <- read_csv("datasets/sleepDay.csv")
weightLogInfo <- read_csv("datasets/weightLogInfo.csv")
```

**Converting column names**  
We'll then use the janitor package to change our column names to snake_case from UpperCamelCase to improve readability:

```{r eval=FALSE} 
dailyActivity <- clean_names(dailyActivity)
sleepDay <- clean_names(sleepDay)
weightLogInfo <- clean_names (weightLogInfo)
```

**Identifying duplicate records**  
Also using the janitor package, let's see if there are any duplicate values in any of our 3 data frames:

```{}
get_dupes(dailyActivity)

No variable names specified - using all columns.

No duplicate combinations found of: id, activity_date, total_steps, total_distance, tracker_distance, logged_activities_distance, very_active_distance, moderately_active_distance, light_active_distance, ... and 6 other variables

get_dupes(sleepDay)

No variable names specified - using all columns.
# A tibble: 6 × 6
          id sleep_day total_sleep_records total_minutes_asleep total_time_in_bed dupe_count
       <dbl> <chr>                   <dbl>                <dbl>             <dbl>      <int>
1 4388161847 5/5/2016                    1                  471               495          2
2 4388161847 5/5/2016                    1                  471               495          2
3 4702921684 5/7/2016                    1                  520               543          2
4 4702921684 5/7/2016                    1                  520               543          2
5 8378563200 4/25/2016                   1                  388               402          2
6 8378563200 4/25/2016                   1                  388               402          2

get_dupes(weightLogInfo)

No variable names specified - using all columns.

No duplicate combinations found of: id, date, weight_kg, weight_pounds, fat, bmi, is_manual_report, log_id
```

It appears we have 6 duplicate records, all in the sleepDay data frame. 

**Removing duplicate and invalid records**  
We want to remove our previously-identified duplicate records, along with the records with 0 total steps as mentioned previously. For this, we will be using the dplyr package, which has already been loaded as part of the tidyverse:

```{r, eval=FALSE}
sleepDay <- distinct(sleepDay)
```

This operation removed 3 duplicated records from our data frame, as expected.

We'll proceed to removing the 98 records from dailyActivity with total_steps < 500, also using dplyr:

```{r, eval=FALSE}
dailyActivity <- dailyActivity %>% 
  filter(total_steps >= 500)
```

This operation leaves the dailyActivity data frame with 842 rows, as expected.

**Identifying and removing outliers**  
Having removed our unwanted rows, we are now able to run some statistical summaries on our data frames without skewing the results due to zero values and duplicates. For this, we'll use the skimr package we loaded earlier. We call skim_without_charts() first on dailyActivity, with the exception of the id column as it is not numerical data:

```{r eval=FALSE}
skim_without_charts(dailyActivity, !id)
```

```{}
── Data Summary ────────────────────────
                           Values       
Name                       dailyActivity
Number of rows             842          
Number of columns          14           
_______________________                 
Column type frequency:                  
  Date                     1            
  factor                   1            
  numeric                  11           
________________________                
Group variables            None         

── Variable type: Date ────────────────────────────────────────────────────────────────────────────────────────────
  skim_variable n_missing complete_rate min        max        median     n_unique
1 activity_date         0             1 2016-04-12 2016-05-12 2016-04-26       31

── Variable type: factor ──────────────────────────────────────────────────────────────────────────────────────────
  skim_variable n_missing complete_rate ordered n_unique top_counts                            
1 weekday               0             1 TRUE           7 Wed: 136, Tue: 135, Thu: 130, Fri: 117

── Variable type: numeric ─────────────────────────────────────────────────────────────────────────────────────────
   skim_variable              n_missing complete_rate     mean       sd      p0     p25      p50       p75     p100
 1 total_steps                        0             1 8523.    4622.    590     5093    8198.    11168.    36019   
 2 total_distance                     0             1    6.13     3.65    0.420    3.51    5.71      8.02     28.0 
 3 tracker_distance                   0             1    6.11     3.63    0.420    3.51    5.71      8.00     28.0 
 4 very_active_distance               0             1    1.68     2.76    0        0       0.470     2.32     21.9 
 5 moderately_active_distance         0             1    0.633    0.911   0        0       0.325     0.880     6.48
 6 light_active_distance              0             1    3.73     1.79    0        2.41    3.66      4.92     10.7 
 7 very_active_minutes                0             1   23.6     33.9     0        0       8        36       210   
 8 fairly_active_minutes              0             1   15.1     20.6     0        0       8        21       143   
 9 lightly_active_minutes             0             1  215.      92.6     0      151     212.      274.      518   
10 sedentary_minutes                  0             1  949.     272.     13      720    1018.     1182      1440   
11 calories                           0             1 2380.     697.     52     1876.   2234.     2846      4900     
```

The attribute that stands out most is the left-skewness of some variables, namely:

* logged_activities_distance
* sedentary_active_distance

This implies that these columns contain mostly zero or near-zero values. For logged_activities_distance, it is likely that most users did not log "activities" while wearing their fitness trackers. For sedentary_active_distance, it appears that very little distance was logged while users were sedentary - a logical conclusion. As such, these two columns have little value for later analysis, and we will remove them from our data frame accordingly.

```{r, eval=FALSE}
dailyActivity <- select(
    dailyActivity, 
    -c(logged_activities_distance, sedentary_active_distance)
  )
```

Moving on, we'll call skim_without_charts() on sleepDay:

```{r, eval=FALSE}
skim_without_charts(sleepDay, !id)
```

```{}
── Data Summary ────────────────────────
                           Values  
Name                       sleepDay
Number of rows             413     
Number of columns          5       
_______________________            
Column type frequency:             
  character                1       
  numeric                  3       
________________________           
Group variables            None    

── Variable type: character ─────────────────────────────────────────────────────
  skim_variable n_missing complete_rate min max empty n_unique whitespace
1 sleep_day             0             1   8   9     0       31          0

── Variable type: numeric ───────────────────────────────────────────────────────
  skim_variable        n_missing complete_rate   mean      sd p0 p25 p50 p75 p100
1 total_sleep_records          0             1   1.12   0.346  1   1   1   1    3
2 total_minutes_asleep         0             1 419.   118.    58 361 433 490  796
3 total_time_in_bed            0             1 459.   127.    61 403 463 526  961
```

This data frame does not appear to have any missing values or statistical oddities warranting removal. However, looking at the data frame directly reveals that many users did not log their sleep every day, with some logging as few as 1 in the span of 29 days. This suggests to us that the sleep tracking function must be manually activated by the user each night.

Finally, we will skim weightLogInfo, removing log_id as well:

```{r, eval=FALSE}
weightLogInfo %>% 
  select(-c(id, log_id)) %>% 
  skim_without_charts()
```

```{}
── Data Summary ────────────────────────
                           Values    
Name                       Piped data
Number of rows             67        
Number of columns          6         
_______________________              
Column type frequency:               
  character                1         
  logical                  1         
  numeric                  4         
________________________             
Group variables            None      

── Variable type: character ─────────────────────────────────────────────────────
  skim_variable n_missing complete_rate min max empty n_unique whitespace
1 date                  0             1   8   9     0       31          0

── Variable type: logical ───────────────────────────────────────────────────────
  skim_variable    n_missing complete_rate  mean count           
1 is_manual_report         0             1 0.612 TRU: 41, FAL: 26

── Variable type: numeric ───────────────────────────────────────────────────────
  skim_variable n_missing complete_rate  mean    sd    p0   p25   p50   p75  p100
1 weight_kg             0        1       72.0 13.9   52.6  61.4  62.5  85.0 134. 
2 weight_pounds         0        1      159.  30.7  116.  135.  138.  188.  294. 
3 fat                  65        0.0299  23.5  2.12  22    22.8  23.5  24.2  25  
4 bmi                   0        1       25.2  3.07  21.5  24.0  24.4  25.6  47.5
```
We can see that the 'fat' column has a completeness of only 3%, with 65 missing values. We'll remove this column as it is of little value to our later analysis.

Similarly to the sleepDay data frame, many users did not log their weight every day. Indeed, there is a true/false column named 'is_manual_report', suggesting that users must manually report unless they also use a Fitbit smart scale to measure their weight.

We also have a 'log_id' column (filtered out of the data summary) which is not seen in our other data frames. Since it is not numerical data and also cannot be used to perform joins, we'll remove this column.

```{r, eval=FALSE}
weightLogInfo <- select(
    weightLogInfo, 
    -c(fat, log_id)
  )
```

With our data cleaned, we can move on to the analysis phase of this study.

## Analysis and Visualizations
For our analysis, we will focus on analyzing usage data to find trends in smart device usage, and apply that information to generate recommendations for future Bellabeat products and marketing initiatives in the final section.

**Trend 1: Low usage of manual reporting functions**  
On a general level, we've already found some insights from our earlier data exploration, namely:

* Fitness tracker users mostly do not log fitness activities manually and generally rely on the automatic collection of health data instead
* The weight and sleep logs rely on manual reporting and is underused, with many missing values and dates

We can visualize this quickly with Tableau by plotting data points for each user ID over our time frame:

***sleepDay***  
![](./images/sleepDay_tracker_use.png)

***weightLogInfo***  
![](./images/weightLog_tracker_use.png)

As we can see, only 3 users successfully tracked their sleep every day, and 0 users tracked their weight every day over our 29-day time frame. This suggests that users do not favor manual reporting.

**Trend 2: Users exercise more at the start of a week and on weekends**  
Currently, our activity_date column's data type is 'character'. We'll first change this to a date using lubridate:
```{r, eval=FALSE}
dailyActivity$activity_date <- as_date(dailyActivity$activity_date, format = "%m/%d/%Y")
```

We then add a new column specifying day-of-week within dailyActivity:
```{r, eval=FALSE}
dailyActivity <- dailyActivity %>% 
  mutate(weekday = wday(activity_date, label = TRUE))
```

We then plot with ggplot:
```{r, eval=FALSE}
dailyActivity %>% 
  group_by(weekday) %>% 
  ggplot(aes(x = weekday, y = total_steps)) +
  geom_boxplot() +
  labs(
    title = "Total Steps Taken by Day of Week",
    x = "Day of Week",
    y = "Total Steps Taken",
    caption = "Time frame: April 12, 2016 to May 11, 2016"
  )
```
![](./images/total_steps_taken_day_of_week.png)
Here, we can see a higher median value and interquartile range (IQR) for Mondays and Tuesdays compared to other weekday days. The day with the highest IQR is Saturday.

We also observe the highest maximum whisker (Q3 + 1.5 * IQR) on Saturday, and the largest outlier on Sunday. 

This suggests to us that, on average, the Fitbit users in this dataset exercised the most on Monday, Tuesday, and Saturday, and that long, strenuous exercise sessions are more likely to occur on weekends. 

**Trend 3: Many users do not wear their trackers all day**  
We first add a new column, total_time_worn, that sums up very active/moderately active/light active/sedentary minutes:
```{r, eval=FALSE}
dailyActivity <- dailyActivity %>% 
  mutate(total_time_worn = very_active_minutes + fairly_active_minutes + lightly_active_minutes + sedentary_minutes)
```

We then create a violin/box plot to visualize:
```{r, eval=FALSE}
dailyActivity %>% 
  group_by(weekday) %>% 
  ggplot(aes(x = weekday, y = total_time_worn)) +
  geom_violin() +
  geom_boxplot(width = 0.1) +
  labs(
    title = "Tracker Use by Day of Week",
    x = "Day of Week",
    y = "Percentage of Day Worn",
    caption = "Time frame: April 12, 2016 to May 11, 2016"
  ) +
  scale_y_continuous(
    breaks = c(360, 720, 1080, 1440),
    labels = c("25%", "50%", "75%", "100%")
  )
```
![](./images/tracker_use_day_of_week.png)
Here, we see that a significant number of users only wear their trackers between 50-75% of the day.

## Recommendations
As a part of our recommendations, we aim to answer our key questions of how these insights apply to Bellabeat users, and how they can be used to improve Bellabeat's marketing strategy.

#### Recommendation 1

#### Recommendation 2

#### Recommendation 3

